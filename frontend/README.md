# Matrix Terminal Frontend

Una interfaz de terminal estilo Matrix para chat con IA, construida con Next.js y styled-components.

## CaracterÃ­sticas

- ğŸ¨ **Interfaz estilo Matrix**: Texto verde sobre fondo negro con efectos visuales
- ğŸ’¬ **Chat en tiempo real**: Streaming de respuestas desde el backend
- ğŸ” **ConfiguraciÃ³n segura**: Almacenamiento local de API key
- ğŸš€ **Modo Demo**: Funciona sin API key usando clave temporal del servidor
- âŒ¨ï¸ **Controles de teclado**: ENTER para enviar, CTRL+C para limpiar
- ğŸ“± **Responsive**: Funciona en diferentes tamaÃ±os de pantalla
- âš¡ **Performance**: Optimizado con Next.js 14

## TecnologÃ­as

- **Next.js 14** - Framework de React
- **TypeScript** - Tipado estÃ¡tico
- **styled-components** - Estilos CSS-in-JS
- **FastAPI** - Backend (puerto 8000)

## InstalaciÃ³n

1. Instalar dependencias:
```bash
npm install
```

2. Ejecutar en modo desarrollo:
```bash
npm run dev
```

3. Abrir [http://localhost:3000](http://localhost:3000)

## ConfiguraciÃ³n

### Backend
AsegÃºrate de que el backend FastAPI estÃ© ejecutÃ¡ndose en `http://localhost:8000`:

```bash
cd ../api
pip install -r requirements.txt
python app.py
```

### API Key
1. ObtÃ©n tu API key de OpenAI en [platform.openai.com](https://platform.openai.com/api-keys)
2. Ingresa la clave en la pantalla de configuraciÃ³n inicial
3. La clave se almacena localmente y nunca se comparte

### Modo Demo
1. Haz clic en "Use Demo" en la esquina superior derecha
2. El modo demo usa una clave temporal del servidor
3. No se requiere API key personal
4. Funciona inmediatamente en Vercel

## Uso

### Controles
- **ENTER**: Enviar mensaje
- **SHIFT + ENTER**: Nueva lÃ­nea
- **CTRL + C**: Limpiar input
- **ESC**: Salir (en desarrollo)

### Estructura del Proyecto

```
frontend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ demo/
â”‚   â”‚       â””â”€â”€ route.ts          # API route para modo demo
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ Terminal.tsx          # Componente principal
â”‚   â”‚   â”œâ”€â”€ ChatMessage.tsx       # Mensajes individuales
â”‚   â”‚   â”œâ”€â”€ InputArea.tsx         # Ãrea de entrada
â”‚   â”‚   â”œâ”€â”€ MatrixBackground.tsx  # Fondo animado
â”‚   â”‚   â”œâ”€â”€ DemoToggle.tsx        # Toggle para modo demo
â”‚   â”‚   â””â”€â”€ DemoBanner.tsx        # Banner de modo demo
â”‚   â”œâ”€â”€ styles/
â”‚   â”‚   â””â”€â”€ GlobalStyles.tsx      # Estilos globales
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â””â”€â”€ registry.tsx          # ConfiguraciÃ³n styled-components
â”‚   â”œâ”€â”€ layout.tsx                # Layout principal
â”‚   â””â”€â”€ page.tsx                  # PÃ¡gina principal
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ demoMode.ts               # Helper para detectar modo demo
â”œâ”€â”€ package.json
â”œâ”€â”€ next.config.js
â”œâ”€â”€ vercel.json                   # ConfiguraciÃ³n de Vercel
â””â”€â”€ tsconfig.json
```

## API Integration

### Modo Normal (Backend FastAPI)
El frontend envÃ­a requests al endpoint `/api/chat` con la siguiente estructura JSON:

```json
{
  "developer_message": "Eres un asistente de IA Ãºtil y amigable...",
  "user_message": "Mensaje del usuario",
  "model": "gpt-4.1-mini",
  "api_key": "sk-proj-..."
}
```

Esto coincide exactamente con el modelo Pydantic `ChatRequest` del backend.

### Modo Demo (API Route Local)
En modo demo, el frontend usa la API route `/api/demo` que maneja las llamadas a OpenAI server-side:

```json
{
  "messages": [
    {"role": "system", "content": "Eres un asistente de IA Ãºtil..."},
    {"role": "user", "content": "Mensaje del usuario"}
  ],
  "model": "gpt-4o-mini"
}
```

## Vercel Deployment

### ConfiguraciÃ³n del Proyecto
1. **Root Directory**: `frontend` (ya configurado)
2. **Framework Preset**: Next.js

### Variables de Entorno
En Project Settings â†’ Environment Variables, aÃ±ade:

```
DEMO_OPENAI_API_KEY = <tu_clave_temporal_de_openai>
```

**Importante**: 
- No expongas esta clave en el frontend
- Usa una clave temporal o de prueba
- La clave se usa solo server-side en la API route

### Deploy
1. Conecta tu repositorio a Vercel
2. Configura las variables de entorno
3. Deploy automÃ¡tico en cada push
4. El modo demo funciona inmediatamente sin configuraciÃ³n adicional

```json
{
  "developer_message": "Eres un asistente de IA Ãºtil y amigable...",
  "user_message": "Mensaje del usuario",
  "model": "gpt-4.1-mini",
  "api_key": "sk-proj-..."
}
```

Esto coincide exactamente con el modelo Pydantic `ChatRequest` del backend.

## Scripts Disponibles

- `npm run dev` - Servidor de desarrollo
- `npm run build` - Construir para producciÃ³n
- `npm run start` - Servidor de producciÃ³n
- `npm run lint` - Verificar cÃ³digo

## PersonalizaciÃ³n

### Colores
Los colores principales estÃ¡n definidos en `GlobalStyles.tsx`:
- Verde Matrix: `#00ff00`
- Verde secundario: `#00cc00`
- Verde suave: `#00aa00`

### Fuentes
- Principal: `'Courier New', monospace`
- TamaÃ±os: 12px, 14px, 16px, 18px, 24px, 28px

## Troubleshooting

### Error de conexiÃ³n
- Verifica que el backend estÃ© ejecutÃ¡ndose en puerto 8000
- Revisa la consola del navegador para errores CORS

### Problemas de API
- Verifica que tu API key sea vÃ¡lida
- AsegÃºrate de tener crÃ©ditos en tu cuenta de OpenAI

### Problemas de estilos
- Verifica que styled-components estÃ© configurado correctamente
- Revisa el archivo `registry.ts` y `next.config.js`

## ContribuciÃ³n

1. Fork el proyecto
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Abre un Pull Request

## Licencia

Este proyecto estÃ¡ bajo la licencia MIT.